{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36e547d-ebca-4b68-a7f2-7ba06e5d2588",
   "metadata": {},
   "source": [
    "# WORD EMBEDDINGS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73e183-3bfc-4ee8-af52-cd1bd43ddfc0",
   "metadata": {},
   "source": [
    "## Frequency based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fb7142-42f0-4864-9f1b-ce0e364cadec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/verykul/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/verykul/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "import numpy as np \n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a566e6-4bd3-46aa-8437-8994e15473e9",
   "metadata": {},
   "source": [
    "## 1. One Hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677535c0-214d-45ce-927b-a127f8831004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'data', 'science', '.', 'Machine', 'learning', 'is', 'part', 'of']\n"
     ]
    }
   ],
   "source": [
    "text = 'I love data science. Machine learning is part of data science'\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "seen = set()\n",
    "\n",
    "vocabulary = []\n",
    "for word in tokens:\n",
    "    if word not in seen:\n",
    "        seen.add(word)\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a7e84-be3c-4a2d-b87e-2072be2e631b",
   "metadata": {},
   "source": [
    "## 2. Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567be8c0-1b4e-4ee1-a353-6a62cc14a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd46ee3-f489-4422-b942-0c2490fbaeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voacbulary: ['am' 'happy' 'learning' 'nlp' 'not' 'sad']\n",
      "\n",
      " Resulting vector space: \n",
      "[[2 1 1 1 0 0]\n",
      " [1 1 0 0 0 0]\n",
      " [2 0 1 1 1 1]\n",
      " [1 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"I am happy, I am learning NLP.\",\n",
    "    \"I am happy\",\n",
    "    \"I am sad, I am not learning NLP\",\n",
    "    \"I am sad\",\n",
    "]\n",
    "X = cv.fit_transform(corpus)\n",
    "print(f\"voacbulary: {cv.get_feature_names_out()}\")\n",
    "print()\n",
    "print(f\" Resulting vector space: \\n{X.toarray()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63651ca0-2cc6-4a39-8335-011a82994cb1",
   "metadata": {},
   "source": [
    "# 3. N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae631f84-a41d-4c5b-9cbd-526ab07b3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = CountVectorizer(ngram_range=(2,2), stop_words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21655637-c1ae-4c8f-91dd-390e5a44248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voacbulary: ['am happy' 'am learning' 'am not' 'am sad' 'happy am' 'learning nlp'\n",
      " 'not learning' 'sad am']\n",
      "\n",
      " Resulting vector space: \n",
      "[[1 1 0 0 1 1 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 1 1 1]\n",
      " [0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"I am happy, I am learning NLP.\",\n",
    "    \"I am happy\",\n",
    "    \"I am sad, I am not learning NLP\",\n",
    "    \"I am sad\",\n",
    "]\n",
    "\n",
    "X = n_grams.fit_transform(corpus)\n",
    "print(f\"voacbulary: {n_grams.get_feature_names_out()}\")\n",
    "print()\n",
    "print(f\" Resulting vector space: \\n{X.toarray()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb84bba-d07a-4347-a584-a822d84c6810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting vector space:\n",
      "[[1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      "  0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 2 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0\n",
      "  0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0\n",
      "  0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1\n",
      "  1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\"Compared with other programming languages, Pythonâ€™s class mechanism adds classes with a minimum of new syntax and semantics. It is a mixture of the class mechanisms found in C++ and Modula-3.\n",
    "Python classes provide all the standard features of Object Oriented Programming:\n",
    "the class inheritance mechanism allows multiple base classes, a derived class can override any methods of its base class or classes, and a method can call the method of a base class with the same name.\n",
    "Objects can contain arbitrary amounts and kinds of data.\n",
    "As is true for modules, classes partake of the dynamic nature of Python: they are created at runtime, and can be modified further after creation.\n",
    "\"\"\"\n",
    "\n",
    "tokens = sent_tokenize(corpus)\n",
    "X = n_grams.fit_transform(tokens)\n",
    "print(f\"Resulting vector space:\\n{X.toarray()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d239b6-6da4-466e-931f-d715f9ed8b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3e918-53c8-412a-98fa-f6e28e135831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
